# 一、进程，线程，协程的区别

1. **进程：**
   - **定义与特点：** 进程是==操作系统资源分配和调度的基本单位==，具有==独立的内存空间==。进程间通信（IPC）可以通过共享内存、消息队列（MQ）、管道等方式实现。
   - **安全与隔离：** 进程间的内存空间是独立的，这提供了较高的安全性和隔离性，但同时也增加了通信的复杂性。

2. **线程：**
   - **定义与特点：** 线程是==CPU调度的基本单位==，一个进程可以包含多个线程。线程享有进程资源，但自身只拥有少量的独立资源，如==栈==。
   - **通信方式：** 线程之间可以通过队列、信号机制（如 `wait`, `notify`, `signal`）、交换器（`Exchanger`）、以及共享变量等方式进行通信。线程间的通信比进程间通信更高效，因为它们共享相同的内存空间。

3. **协程：**
   - **定义与特点：** 协程是一种==用户态的轻量级线程==，程序员可以显式控制其调度。协程的切换开销较小，因为它们==避免了内核态与用户态之间的切换==。
   - **优势与用途：** 协程相对于线程更加==轻量==（通常只占用几KB的内存），能简化并发编程的复杂性，类似于==串行执行==。它们尤其适用于IO密集型任务，可以==减少上下文切换的性能损耗==。
   - **线程安全：** 由于协程可以避免使用锁等机制，因此在多协程环境下编写线程安全的代码更为简便。

# 二、Java中创建线程方式

1. **继承 `Thread` 类：**
   - **方法描述：** 通过继承 `Thread` 类并覆写其 `run()` 方法来创建线程。这种方式直接使用了 `Thread` 类的功能，但因为Java不支持多继承，所以这种方法可能限制了类的扩展性。
   - **示例用法：**
     
     ```java
     public class MyThread extends Thread {
         public void run() {
             // 线程执行的代码
         }
     }
     MyThread t = new MyThread();
     t.start();
     ```
   
2. **实现 `Runnable` 接口：**
   - **方法描述：** 这是创建线程的推荐方式。通过实现 `Runnable` 接口的 `run()` 方法，然后将 `Runnable` 对象传递给 `Thread` 类的构造函数。这种方法更灵活，允许类继续扩展其他类。
   - **示例用法：**
     ```java
     public class MyRunnable implements Runnable {
         public void run() {
             // 线程执行的代码
         }
     }
     Thread t = new Thread(new MyRunnable());
     t.start();
     ```

3. **使用 `Callable` 和 `FutureTask`：**
   - **方法描述：** `Callable` 是一个返回结果并可能抛出异常的任务。它通常与 `FutureTask` 结合使用，后者是 `RunnableFuture` 的一个实现，它同时实现了 `Runnable` 和 `Future` 接口。这允许线程执行完成后从其中获取结果。
   - **示例用法：**
     
     ```java
     public class MyCallable implements Callable<Integer> {
         public Integer call() throws Exception {
             return 123;  // 返回结果
         }
     }
     FutureTask<Integer> future = new FutureTask<>(new MyCallable());
     Thread t = new Thread(future);
     t.start();
     ```
   
4. **使用线程池：**
   - **方法描述：** 线程池是一种通过预先创建线程的集合来执行任务的机制，它可以有效地管理被创建线程的数量。线程池中的工作线程本质上是实现了 `Runnable` 的 `Worker` 对象。
   - **示例用法：**
     
     ```java
     ExecutorService executor = Executors.newFixedThreadPool(10);
     executor.execute(new MyRunnable());  // 提交任务
     executor.shutdown();  // 关闭线程池
     ```


在Java中，虽然有多种方式创建线程，但==本质上都是基于 `Runnable` 接口的实现==。这确保了在Java中创建线程的统一性和灵活性。这样的理解有助于在实际编程中选择最合适的线程实现方式。

# 三、如何结束线程

> `stop()` 方法虽然可以立即终止线程，但它是不安全的，因为它强制线程停止正在执行的任何操作，可能导致对象处于不一致状态或者锁定资源未被释放。

- **通过正常结束 `run()` 方法：**
  
  最自然的线程终止方式是让 `run()` 方法执行完毕。这种方法简单明了，可以通过循环结束或达到任务完成条件自然退出。

- **异常结束：**
  
   Java线程中有一个内部的中断状态标记，可以通过调用线程的 `interrupt()` 方法来设置这个标记为 `true`。
  
  - **检查中断状态：**
  
    ```java
    while (!Thread.currentThread().isInterrupted()) {
        // 线程的工作代码
    }
    ```
  - **响应中断：** 当线程处于阻塞状态（如正在 `sleep`, `wait`, `join` 等），如果它被中断，阻塞调用将会抛出 `InterruptedException`，此时可以捕获这个异常并适当清理资源后退出。
  
    ```java
    try {
        Thread.sleep(1000);
    } catch (InterruptedException e) {
        // 清理工作，准备结束线程
        Thread.currentThread().interrupt();  // 可选，重新设置中断状态
    }
    ```
  
   在线程的 `run()` 方法中，使用一个共享变量（通常为 `volatile` 类型以保证可见性）控制循环或执行条件。
  
  - **示例：**
  
    ```java
    public class MyRunnable implements Runnable {
        private volatile boolean running = true;
    
        public void run() {
            while (running) {
                // 执行任务
            }
        }
    
        public void stopRunning() {
            running = false;
        }
    }
    ```

# 四、ThreadLocal的作用和内存泄漏问题

## 1.ThreadLocal 的作用
- **线程局部存储：** `ThreadLocal` 提供了一种线程安全的方式来存储数据，==使得数据只属于一个特定的线程==，而不会在多个线程间共享。在使用线程池或者并发场景下，它可以为每个线程提供独立的实例，例如用户会话、数据库连接等，从而避免并发问题。

### 2.内存泄漏问题
`ThreadLocal` 可能导致内存泄漏的主要原因与其使用的 `ThreadLocalMap` 结构有关，这是一个以 `ThreadLocal` 对象为键、以线程局部变量为值的映射。关于内存泄漏，有两个主要问题：

1. **Key的内存泄漏：**
   - **问题描述：** 如果一个 `ThreadLocal` 没有外部强引用时，通常发生在将`ThreadLocal`作为局部变量进行使用，在下一次垃圾回收时，其 `ThreadLocal` 理应会被回收，但因为 `ThreadLocalMap` 的存在，对`key`进行了引用，因此`ThreadLocal`作为根可达对象不会被回收。
   - **解决方式：** 通过使用==弱引用作为键==，确保 `ThreadLocal` 对象本身可以被垃圾收集器回收

2. **Value的内存泄漏：**
   - **问题描述：** 当线程结束后，其 `ThreadLocalMap` 中的数据通常会被自动清除。然而，在使用线程池的情况下，线程并不会结束，而是被重新用于其他任务。如果不==显式清除== `ThreadLocal` 存储的数据，这些数据会一直留在线程中，从而导致内存泄漏。
   - **解决方式：** 在任务执行完毕后，通过调用 `ThreadLocal.remove()` 方法清除数据，特别是在使用线程池的情况下非常重要。

# 五、伪共享问题以及处理方案

伪共享（False Sharing）发生在多个线程访问并修改相同缓存行（Cache Line）上的不同变量时，尽管这些变量是独立的，但由于它们位于同一个缓存行内，所造成的缓存无效化会导致性能下降。

### 伪共享的原理
 现代CPU使用缓存来减少访问主内存的时间。CPU缓存被组织成多个缓存行，通常每个缓存行为64字节。 当多个线程修改同一个缓存行内的不同数据时，尽管这些数据彼此独立，但任一数据的修改都会导致整个缓存行被标记为脏数据，从而导致其他处理器核心中该缓存行的副本失效。这迫使其他核心在再次访问其数据时不得不从主内存重新加载整个缓存行，增加了延迟和带宽需求。

### 解决伪共享的方法
为了防止伪共享，可以在经常被多个线程访问的变量之间人为地添加填充（如额外的字节），以确保它们不会出现在同一个缓存行上。在Java中，这可以通过添加无用的变量来间隔真正的共享变量，或使用Java 8引入的`@Contended`注解，这个注解可以自动帮助开发者避免伪共享，但需要在JVM启动时加上`-XX:-RestrictContended`来启用。

以下是一个使用填充避免伪共享的Java示例：
```java
public class FalseSharingExample implements Runnable {
    private static final int NUM_THREADS = 2; // 线程数
    private static final int NUM_VALUES = 1024; // 模拟大量变量
    private static final PaddedLong[] paddedLongs = new PaddedLong[NUM_VALUES];

    static {
        for (int i = 0; i < NUM_VALUES; i++) {
            paddedLongs[i] = new PaddedLong();
        }
    }

    private final int arrayIndex;

    private FalseSharingExample(int arrayIndex) {
        this.arrayIndex = arrayIndex;
    }

    @Override
    public void run() {
        for (int i = 0; i < 100_000_000; i++) {
            paddedLongs[arrayIndex].value = i;
        }
    }

    private static final class PaddedLong {
        public volatile long value = 0L;
        // 填充避免伪共享
        public long p1, p2, p3, p4, p5, p6, p7;
    }

    public static void main(String[] args) throws InterruptedException {
        Thread[] threads = new Thread[NUM_THREADS];
        for (int i = 0; i < threads.length; i++) {
            threads[i] = new Thread(new FalseSharingExample(i));
        }
        for (Thread t : threads) {
            t.start();
        }
        for (Thread t : threads) {
            t.join();
        }
    }
}
```
这个示例中，每个 `PaddedLong` 对象通过添加多余的变量 `p1` 到 `p7` 来保证 `value` 独占一个缓存行，从而减少由伪共享带来的性能影响。

您提到的CPU缓存可见性问题是并发编程中一个重要的问题，它涉及到多核处理器环境下的数据一致性和可见性。这个问题是由现代CPU的缓存系统和优化机制所引起的，下面我将详细解释这个问题的原因以及处理方式。

# 六、CPU缓存可见性

### CPU缓存可见性问题的原因
1. **MESI协议的角色：**
   - **MESI协议（Modified, Exclusive, Shared, Invalid）：** 一种缓存一致性协议，用于维护不同CPU核心缓存中的数据一致性。每个缓存行的状态都会根据是否被修改、是否被独占、是否被共享或是否无效而变化。MESI协议确保一个核心对数据的修改能够被其他核心感知，通过将缓存行标记为无效或更新其内容。
2. **优化机制的影响（如StoreBuffer，Invalidate Queue）：**
   - **StoreBuffer：** 用于存储写操作的缓冲区，它允许CPU将写操作暂存，从而不立即写回到主内存，这样CPU可以继续处理其他操作，增强执行效率。然而，这可能导致其他核心看到的数据是过时的。
   - **Invalidate Queue：** 当一个核心需要将缓存行的数据无效化时（因为数据已被另一个核心修改），这个队列管理着无效化的通知。但是，处理这些通知的速度可能影响数据的实时更新。

### 使用`lock`前缀指令
- **lock前缀指令：**
   - 这是x86处理器指令集中的一个特性，用于在执行某些操作时确保操作的原子性和可见性。当使用`lock`前缀执行指令时，==处理器将确保这条指令对内存的修改立即被写回到主内存==，并触发MESI协议，确保所有其他CPU核心的缓存行都是最新的或被标记为无效。
   - 这种方法有效地绕过了StoreBuffer和Invalidate Queue可能引起的延迟问题，保证了操作的即时可见性。



# 七、单例模式的DCL加volatile

在Java中实现单例模式时，特别是使用懒汉式单例模式和双重检查锁定（DCL，Double-Checked Locking）时，确实需要关注线程安全和指令重排的问题。在懒汉式单例模式中，如果不使用`volatile`关键字修饰单例实例，可能会遇到指令重排的问题。这是因为在Java中，对象的创建过程并非原子操作，通常涉及以下三个步骤：

1. **分配内存空间：** 给新对象分配内存。
2. **初始化对象：** 调用构造方法，初始化对象内部的字段。
3. **设置引用：** 将对象的引用指向分配的内存空间。

如果没有`volatile`关键字，编译器和处理器为了优化性能，可能会重排这些指令。例如，指令重排可能导致步骤3在步骤2之前发生，这就意味着在对象完全构造完成之前，就已经将内存地址赋给了引用。

考虑下面的情况：线程A执行单例的`getInstance()`方法，并且执行到第二次检查`if(myTest == null)`，假设此时线程B也调用了`getInstance()`方法。由于指令重排，线程A可能已经把分配的内存地址赋给了`myTest`，但对象的初始化（步骤2）可能还未完成。此时，线程B检查`myTest`不为`null`，直接返回了`myTest`对象。如果B线程此时访问`myTest`对象的任何属性，就可能引发空指针异常，因为对象可能还未被完全初始化。

使用`volatile`关键字修饰`myTest`变量后，它会有两个主要的效果：

1. **防止指令重排：** 确保声明为`volatile`的变量的写操作之前的操作在内存中不会被重排到写操作之后。
2. **保证可见性：** 确保修改`volatile`变量时，值会立即被更新到主内存中，同时确保每次访问`volatile`变量时都从主内存中重新读取。

当`volatile`变量被写入时，Java虚拟机会插入一个特定类型的内存屏障（`StoreStore`/`StoreLoad`屏障），这阻止了变量赋值后的任何指令与之前的指令重排。在x86架构下，这通过插入一个`mfence`指令实现，这是一个全屏障，确保之前的所有读写操作在内存中对其他处理器都可见之后，才执行后续操作。

因此，为了避免上述多线程环境中的潜在问题和保证单例模式的线程安全，使用`volatile`关键字是关键的设计决策之一。

# 八、CAS

CAS（Compare-And-Swap）操作是一种系统原语，直接由处理器提供支持。它涉及三个操作数——内存位置（V），预期原值（A）和新值（B）。如果内存位置的值与预期原值相同，处理器会自动将该位置值更新为新值。这个操作是原子的，意味着在完成这个操作的过程中，不会被其他线程打断。

在Java中，CAS操作通过`Unsafe`类的`compareAndSwapInt`等方法提供。这些方法是用本地代码（C/C++）实现的，并直接构建在底层硬件的CAS指令之上。

- **`compareAndSwapInt` 方法的参数说明：**
  - `Object var1`：要修改的对象。
  - `long var2`：对象中要修改的字段的内存偏移量。
  - `int var4`：预期的原值。
  - `int var5`：新值。

在底层，Java的CAS操作通过调用本地方法实现，这些本地方法直接映射到CPU提供的原语，如x86架构的`cmpxchg`指令。为了确保在多核处理器上的线程安全，这些指令通常会配合`lock`前缀使用，以避免多个处理器核心同时对同一内存位置进行操作。

**CAS存在的问题**

1. **ABA问题：**
   - 如果一个变量原来是A，后来被改成B，再改回A，使用CAS检查时只会看到A没有变化，从而误认为没有其他线程修改过这个变量。这在某些应用场景下可能导致严重的逻辑错误。
   - **解决方案：** 使用带版本号的原子引用，如`AtomicStampedReference`，这个类通过维护每个值的“时间戳”来确保即便是回到原值，也能感知到中间的改变。

2. **性能问题：**
   - 高冲突环境下，CAS可能导致高CPU消耗。如果多个线程反复尝试更新同一变量，但由于持续的冲突而失败，它们会反复尝试，这种现象称为“自旋”。这可能导致性能问题，尤其是在高负载的系统中。
   - **替代方案：** 如果预期冲突较少，使用CAS是合理的；如果冲突很多，可能需要考虑使用传统的锁机制，如`synchronized`或`ReentrantLock`，这些机制在冲突高时可能更有效。

# 九、锁的类型

### 1. 乐观锁
乐观锁是一种常用的并发控制策略，其核心思想是假设多个事务在执行过程中不会相互冲突，因此在操作过程中不会锁定资源，只在事务提交时检查是否存在冲突。如果发现冲突，则放弃操作或重试。

- **实现方式：**
  - 在Java中，乐观锁通常通过原子类（如`AtomicInteger`）或版本号（在数据记录中添加版本字段）实现。
  - 在数据库中，乐观锁通常通过检查记录的版本号或时间戳来实现。

### 2. 悲观锁
悲观锁与乐观锁相对，它假设冲突总是会发生，因此在整个操作过程中保持资源锁定，直到事务完成。这种锁策略适用于高冲突环境，可以防止数据竞争和不一致。

- **实现方式：**
  - 在Java中，悲观锁可以通过`synchronized`关键字或`Lock`接口实现。
  - 在数据库中，通过SELECT ... FOR UPDATE等SQL语句实现行锁定。

### 3. CAS（Compare-And-Swap）
CAS是一种底层的同步原语，它允许在一个原子操作中比较并交换内存中的值。CAS操作是无锁的，通常用作实现高效的并发数据结构的基础。

- **特点：**
  - CAS不会导致线程挂起，而是使用忙等待（自旋）来处理冲突。
  - 它适用于冲突较少的场景，因为长时间的自旋会浪费CPU资源。

### 4. 自旋锁
自旋锁是一种忙等锁，它通过循环检查锁的状态并在未被锁定时获得锁。自旋锁避免了线程的上下文切换开销，但在锁竞争激烈的情况下会消耗大量CPU资源。

- **实现方式：**
  - 在Java中，自旋锁可以简单通过`while`循环和CAS操作来实现。

### 5. 自适应自旋锁
自适应自旋锁是自旋锁的一个智能版本，它可以根据之前获取锁的历史来动态调整自旋的次数。这种锁的自旋次数不是固定的，而是根据前一次在同一个锁上的自旋时间和锁的状态来调整。

- **特点：**
  - 自适应自旋锁在Java中是`synchronized`关键字在轻量级锁状态下的表现形式。
  - 它优化了自旋的过程，减少了在锁竞争激烈的情况下的CPU资源浪费。

# 十、synchronized的实现原理

`synchronized` 可以用于代码块和方法。对于同步代码块，它使用一个对象实例作为锁：
```java
synchronized(lockObject) {
    // access resources
}
```
对于同步方法，锁可以是实例方法的对象实例（`this`）或者是类方法的类对象（`Class`实例）。

Java中的`synchronized`锁有几种状态，这些状态在JVM内部使用对象监视器（Monitor）实现：
- **无锁状态：**在对象刚被创建时，它处于无锁状态。这意味着对象头（Mark Word）中的锁标志位显示为无锁状态。在JDK 1.8中，存在偏向锁启动延迟（默认为4秒），这意味着对象在这段时间内即使被用作同步代码块的锁对象，也不会立即进入偏向锁状态，而是保持无锁状态。
- **偏向锁状态**：偏向锁是一种优化策略，用于减少锁操作的开销。当偏向锁被启用后，新创建的对象会自动进入偏向锁状态。偏向锁的目的是优化单一线程对锁的重复获取。当锁对象被第一个线程锁定时，其对象头的Mark Word被设置为指向该线程的指针，此后该线程进入同步块时不需进行任何同步操作。如果另一个线程尝试获取这个锁，JVM会撤销偏向锁，并根据竞争情况可能升级到轻量级锁或重量级锁。
- **轻量级锁状态**：当出现轻微的锁竞争，即偏向锁无法使用时，锁会升级为轻量级锁。轻量级锁通过在栈中创建锁记录（Lock Record）来存储锁对象原有的对象头，并尝试使用CAS将对象头替换为指向锁记录的指针。如果这个CAS操作成功，当前线程获得锁；如果失败，表示有竞争。轻量级锁的自适应自旋锁机制会根据前一次在同一个锁上的自旋时间和结果调整自旋次数，以优化性能。
- **重量级锁状态**：如果轻量级锁中的自旋锁重试失败，或者锁竞争较为激烈，锁会升级为重量级锁。重量级锁会挂起无法获取锁的线程，并在锁被释放时唤醒它们。这种锁涉及到操作系统层面的线程阻塞和唤醒，是一种较为昂贵的操作。

**synchronized加锁过程**

1. **锁升级**：在Java 6之后，`synchronized`使用了一种称为锁升级的优化策略。开始时，锁可能处于偏向模式，这时锁偏向第一个访问它的线程，后续的锁操作仅需简单的检查。
2. **轻量级锁**：当有另一个线程尝试获取同一个锁时，偏向锁会升级为轻量级锁。轻量级锁通过在对象头上的锁记录（Mark Word）中CAS操作尝试获取锁。如果尝试成功，当前线程获得锁；如果失败，锁可能进一步升级。
3. **重量级锁**：如果轻量级锁的CAS失败多次，表明有多个线程竞争，锁会升级为重量级锁。此时，未能获取锁的线程会阻塞，直到锁被释放。

解锁过程通常比加锁简单。根据锁的当前状态，JVM会将锁标记归还至初始状态，如果是重量级锁，会唤醒在此对象监视器上等待的线程。

# 十一、AQS

AQS（AbstractQueuedSynchronizer）是Java并发编程中的一个核心组件，其在`java.util.concurrent.locks`包中提供了一个用于构建锁和其他同步组件的框架。AQS是一个抽象类，它为实现依赖于先进先出（FIFO）等待队列的阻塞锁和相关同步器（如信号量、事件等）提供了基础。

**AQS的核心特性**

1. **状态（State）**
   - AQS使用一个`volatile int`类型的变量`state`来表示同步状态。在锁或其他同步器的上下文中，这个状态的意义可以根据需要自定义。例如，在`ReentrantLock`中，`state`可以表示持有锁的次数；在`Semaphore`中，`state`可能表示剩余的许可数。

2. **同步队列（Sync Queue）**
   - 当线程尝试获取但当前无法获取同步状态（例如，锁已被其他线程持有）时，这些线程会被封装成Node对象并加入到同步队列中。这是一个典型的FIFO队列，确保等待资源的线程按顺序获得服务。
   - 当同步状态释放时，队列中的后续节点（通常是等待时间最长的节点）会尝试重新获取状态。

3. **条件队列（Condition Queue）**
   - AQS还支持条件变量，这是用于实现`Condition`接口的节点的单向链表。条件队列用于管理那些调用了条件变量的`await()`方法并因此被阻塞的线程。
   - 当`signal()`或`signalAll()`方法被调用时，线程从条件队列移动到同步队列，再次尝试获取同步状态。

**AQS的工作原理**

AQS定义了一系列用于操作`state`变量的方法，并管理一个双端队列来维护等待获取资源的线程。核心方法包括：

- `acquire(int arg)`：尝试以独占模式获取对象状态。如果获取失败，当前线程将会进入同步队列等待，直到其他线程释放状态。
- `release(int arg)`：以独占模式释放对象状态并唤醒后续节点尝试获取状态。
- `acquireShared(int arg)`：尝试以共享模式获取对象状态。共享模式下，多个线程可以同时获取状态。
- `releaseShared(int arg)`：释放共享模式下的对象状态。

AQS的实现依赖于继承。开发者通过继承AQS并实现其提供的方法来创建自定义的同步组件。例如，`ReentrantLock`通过内部类同步器实现了锁的功能，而`CountDownLatch`使用AQS实现了一个或多个线程等待一组事件完成的功能。

# 十二、ReentrantLock释放锁时从后往前找有效节点

AQS 维护一个双向链表来管理那些尝试获取锁但尚未成功的线程。每个节点（Node）代表一个线程，节点之间通过前驱（prev）和后继（next）指针连接。这个队列的头节点（head）通常是当前持有锁或已释放锁的线程的哨兵节点，而尾节点（tail）则是最后进入队列的节点。

当线程取消等待（可能是因为超时或中断）时，它的节点会从队列中取消，这通常涉及到一些复杂的指针操作，以确保队列的其余部分仍然可用于其他线程。取消节点的 `next` 指针会指向自己，这是为了帮助垃圾收集器识别和回收这些不再需要的节点对象。这样的设计可以防止已取消的节点继续保持活跃的引用，从而避免内存泄漏。

1. **前驱指针的准确性**：在AQS的设计中，前驱指针（prev）被保持为始终指向有效的、活跃的节点，而后继指针（next）可能不准确。当节点取消等待时，它们的 `next` 指针可能被设置为指向自己，但它们的 `prev` 指针仍然指向队列中的前一个有效节点。
2. **性能优化**：从尾部向前查找可以快速定位到需要唤醒的节点，尤其是在高并发环境下，队列后端的线程更有可能是最近才进入队列的，因此有更高的概率是活跃的。这种策略减少了锁的释放和线程唤醒之间的延迟。



# 十三、公平锁和公平锁 

公平锁确保按照线程到达的顺序来获取锁，而非公平锁则允许“插队”，可能导致某些线程饿死（长时间得不到服务）。

### ReentrantLock的公平性和非公平性

`ReentrantLock`提供了两种锁：公平锁和非公平锁。选择哪种类型的锁取决于通过构造函数传递的布尔值（`true`为公平锁，`false`为非公平锁，默认为非公平）。

#### 非公平锁
- **锁获取**：在非公平锁中，当线程请求锁时，它会立即尝试通过CAS操作（比较并交换）来获取锁。这意味着如果锁当前是可用的（`state==0`），它会立刻尝试设置为1（表示锁被一个线程持有）。
- **锁的实现**：如果CAS操作成功，那么当前线程就获取了锁；如果不成功（说明其他线程持有锁），则当前线程加入等待队列。

```java
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

#### 公平锁
- **锁获取**：在公平锁模式中，当线程请求锁时，它会首先检查等待队列是否有其他线程在排队。如果队列中有其他线程，即使锁当前是可用的，当前线程也会加入队列的末尾，以保持队列的公平性。
- **锁的实现**：这防止了线程“插队”，但可能会导致更长的延迟，因为即使锁是可用的，也会先服务于等待队列中的线程。

```java
protected final boolean tryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

### synchronized的非公平性
- `synchronized` 关键字在Java中实现的锁机制默认是非公平的。当一个`synchronized`块被释放时，JVM将从等待锁的线程中随机选择一个线程来获取锁，而不考虑线程等待的顺序。

总结来说，非公平锁可能提供更好的性能（因为它减少了调度的开销），但是可能导致某些线程饿死。公平锁保证了所有线程将按照一定的顺序获得服务，从而防止了饿死的情况，但可能以较高的调度开销为代价。在设计多线程应用程序时，开发者需要根据具体情况选择合适的锁类型。

# 十四、线程池的核心参数

# 十五、线程池配置

# 十六、线程池执行流程

# 十七、拒绝策略

### 1. `AbortPolicy`
这是默认的拒绝策略。当任务被拒绝时，`AbortPolicy`会抛出一个`RejectedExecutionException`。这种策略直接通知调用者任务无法被线程池处理。

### 2. `DiscardPolicy`
这种策略将静默地丢弃无法处理的任务，不抛出异常，也不提供任何通知。如果任务不是关键的，这种策略可以避免因为异常处理导致的系统性能影响。

### 3. `CallerRunsPolicy`
这种策略不会丢弃任务，也不会抛出异常。相反，它会让提交任务的线程自己去执行该任务。这种方式提供了一种简单的反馈控制机制，可以减慢新任务的提交速度。

### 4. `DiscardOldestPolicy`
这种策略将抛弃队列中最老的一个任务（即即将被执行的任务），然后尝试重新提交当前任务。这种策略假设待处理的任务仍然有效，并期望通过牺牲一些任务来为新任务腾出空间。

### 自定义拒绝策略
如果这些预定义的策略不满足特定需求，您可以通过实现`RejectedExecutionHandler`接口来创建自己的拒绝策略。这可以让您根据具体的业务需求，如记录日志、尝试其他方式处理任务、甚至重新调度任务等，更灵活地处理被拒绝的任务。

# 十八、在线程池执行任务前后追加操作

`ThreadPoolExecutor`提供了两个非常有用的勾子方法，`beforeExecute`和`afterExecute`，这使得在任务执行前后进行自定义操作变得可能。这些方法为开发者提供了一个灵活的方式来添加额外的行为，比如日志记录、性能监控、资源管理等，而不需要修改任务本身的实现。

### 1. 继承 `ThreadPoolExecutor`
首先，您需要创建一个`ThreadPoolExecutor`的子类，并覆盖`beforeExecute`和`afterExecute`方法。这样可以确保每次任务执行前后都会调用这些方法。

```java
public class MyThreadPoolExecutor extends ThreadPoolExecutor {
    public MyThreadPoolExecutor(int corePoolSize,
                                int maximumPoolSize,
                                long keepAliveTime,
                                TimeUnit unit,
                                BlockingQueue<Runnable> workQueue,
                                ThreadFactory threadFactory,
                                RejectedExecutionHandler handler) {
        super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler);
    }

    @Override
    protected void beforeExecute(Thread t, Runnable r) {
        super.beforeExecute(t, r);
        // 在任务执行前执行的操作
        System.out.println("Thread " + t.getName() + ": About to start executing " + r.toString());
    }

    @Override
    protected void afterExecute(Runnable r, Throwable t) {
        super.afterExecute(r, t);
        // 在任务执行后执行的操作
        if (t != null) {
            System.out.println("Runnable " + r + " executed with exception: " + t);
        } else {
            System.out.println("Runnable " + r + " executed successfully.");
        }
    }
}
```

### 2. 实现自定义逻辑
在这些方法中，您可以添加任何所需的逻辑。例如：

- **在`beforeExecute`中：**
  - 记录任务开始的时间，用于计算任务执行时长。
  - 检查线程状态或设置特定的线程局部变量。
  - 记录或者验证执行环境的特定条件。

- **在`afterExecute`中：**
  - 计算并记录任务执行时长。
  - 捕捉和记录任务执行中抛出的异常。
  - 进行资源清理操作，比如关闭文件流或数据库连接等。
  - 发送通知或者更新UI（如果在允许的上下文中）。

### 3. 使用自定义线程池
在应用中，您需要使用这个自定义的线程池类来替代标准的`ThreadPoolExecutor`：

```java
int corePoolSize = 4;
int maxPoolSize = 10;
long keepAliveTime = 5000;
TimeUnit timeUnit = TimeUnit.MILLISECONDS;
BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue<>();
ThreadFactory threadFactory = Executors.defaultThreadFactory();
RejectedExecutionHandler handler = new ThreadPoolExecutor.AbortPolicy();

MyThreadPoolExecutor myExecutor = new MyThreadPoolExecutor(
    corePoolSize,
    maxPoolSize,
    keepAliveTime,
    timeUnit,
    workQueue,
    threadFactory,
    handler
);

// Submit tasks to myExecutor
myExecutor.execute(new SomeTask());
```

通过覆盖这些勾子方法，您可以使线程池的行为更加适合您的应用需求，增强其功能和灵活性。这种方法尤其适用于需要细粒度控制线程行为的复杂应用或服务。

# 十九、任务饥饿问题

# 二十、工作线程结束的方式

# 二十一、线程池应用场景

### 1. 异步任务处理
- **场景描述**：在不影响主线程继续执行的情况下，执行如发送邮件、发送短信等后台任务。
- **线程池优势**：线程池可以异步处理这些任务，避免阻塞用户界面或主业务流程，提高响应速度。

### 2. 定时任务执行
- **场景描述**：需要周期性或定时执行的任务，如数据备份、状态检查等。
- **线程池优势**：使用`ScheduledThreadPoolExecutor`，可以精确地控制任务执行的时间和频率，同时避免创建和销毁线程的重复开销。

### 3. 并行数据处理
- **场景描述**：当需要同时访问或调用多个服务，并行处理以减少总体等待时间和提高效率时。
- **线程池优势**：线程池能有效分配和管理线程，使得每个任务都能及时处理，优化资源利用率和响应时间。

### 4. 大规模数据处理
- **场景描述**：处理大量数据，如在数据库操作、文件处理或大数据计算中进行数据导入导出。
- **线程池优势**：通过并行处理，可以显著提高处理效率，特别是在多核处理器的环境下，线程池可以利用多核处理器并行执行多个任务。

### 5. 框架和库的底层支持
- **场景描述**：许多开源框架和库（如消息队列RabbitMQ、Web服务器等）内部使用线程池来处理任务或响应。
- **线程池优势**：配置适当的线程池可以使这些服务处理更多的并发请求，提高性能和吞吐量。

### 额外场景
- **Web服务器请求处理**：Web服务器使用线程池来处理入站的HTTP请求，能够同时处理多个网络请求，提高服务器的响应能力。
- **并发编程环境中的资源管理**：在需要频繁创建和销毁线程的环境中，线程池可以作为一种资源池，重用线程实例，减少系统开销。

使用线程池的一个关键考虑是合理配置线程池的大小和类型，这取决于任务的性质（CPU密集型、IO密集型或混合型）、系统资源（如CPU核心数）和预期的负载。正确的线程池配置可以优化应用程序的性能，避免资源浪费或过度竞争。

# 二十二、ConcurrenHashMap存储结构

# 二十三、ConcurrentHashMap保证写操作线程安全的方式

在并发环境中，使用数组存储数据时，可以通过原子操作（如CAS，即Compare-And-Swap）来保证数据的一致性和线程安全。CAS是一种无锁编程技术，它在硬件级别上支持原子性操作。

对于链表或红黑树这种更复杂的数据结构，使用锁（如`synchronized`）是一种常见的确保线程安全的方法。由于这些数据结构的操作可能涉及多个节点的修改，因此需要确保在修改过程中数据结构的状态保持一致。

# 二十四、ConcurrentHashMap的计数器实现

`AtomicLong`是一个提供原子操作的类，它允许无锁的线程安全操作单个的`long`值。它主要依赖于CAS（Compare-And-Swap）操作来实现线程安全的增加、减少和设置等功能。在高并发场景中，当多个线程频繁更新同一个`AtomicLong`实例的值时，如果竞争激烈，会产生大量的失败CAS尝试，这会导致性能下降，因为每个失败的CAS都要重新读取值、再次尝试，这不仅增加了延迟，还消耗了大量的CPU资源。

为了减少高并发环境下的竞争，`LongAdder`采用了分段的思想，它将热点数据分散到多个变量上，从而减少了单个变量更新操作的竞争。具体来说，`LongAdder`使用了多个`CounterCell`，每个`CounterCell`都包含一个用于计数的独立变量。当更新操作发生时，线程可以映射到任意一个`CounterCell`上执行更新，这大大减少了冲突的概率。

- **工作原理**：
  1. **初始状态**：`LongAdder`维护一个基本值`base`和一个`CounterCell`数组。
  2. **更新操作**：当一个线程需要更新计数器时，它首先尝试在`base`上使用CAS操作进行更新。如果竞争激烈（即有多个线程同时尝试更新`base`），`LongAdder`动态地增加`CounterCell`数组的长度，并将部分更新压力分散到数组的不同`CounterCell`上。
  3. **读取操作**：当需要获取当前的总计数时，`LongAdder`会将`base`和所有`CounterCell`中的值累加起来，以得到最终的结果。
- **优势**：
  - **高并发优化**：在高并发更新场景下，通过分散更新压力到多个`CounterCell`，`LongAdder`减少了单个点的竞争，从而提高了性能。
  - **自适应扩展**：`LongAdder`可以根据竞争情况动态地调整`CounterCell`数组的大小，使其更适合当前的并发水平。

因此，对于`ConcurrentHashMap`这样需要高效并发计数的实现，使用`LongAdder`比`AtomicLong`更合适，因为它在极高的并发情况下能够提供更好的性能。`AtomicLong`尽管也提供了线程安全的计数，但在高并发场景下，其性能会因为CAS操作的竞争而大幅下降。通过使用`LongAdder`，`ConcurrentHashMap`能够更有效地管理并发数据的计数，尤其是在元素数量很大或者并发修改非常频繁的情况下。

# 二十五、ConcurrentHashMap的扩容流程

您对`ConcurrentHashMap`的扩容过程描述得很详细，这是一个复杂但高效的过程，允许多个线程并发地进行数据迁移，以减少扩容对性能的影响。我会补充一些细节并更系统地梳理这一过程：

### 1. 扩容触发时机
`ConcurrentHashMap`中的扩容通常由以下情况触发：
- **链表长度过长**：如果某个桶中的链表长度达到阈值（如8），且数组长度小于64，则可能触发扩容，以减少查找时间。
- **负载因子**：当实际存储的元素数量超过数组长度乘以负载因子（默认为0.75）时，触发扩容。
- **`putAll`操作**：执行`putAll`时，如果加入的元素数量超过当前的阈值，将首先进行扩容。

### 2. 计算扩容标识戳
扩容过程中，使用一个标识戳（或称为迁移戳），这是一个特殊的值，存储在表的内部变量中，用来标记扩容的状态，并记录从哪个数组长度开始扩容。这个戳有助于确保协助扩容的线程正确处理数据。

### 3. 计算迁移步长
迁移步长取决于数组的当前长度和系统的CPU核心数，以确保扩容工作被平均分配到多个线程。通常每个迁移任务至少处理16个桶。

### 4. 创建新数组
新数组的长度通常是原数组的两倍。这有助于分散哈希冲突，并为将来的插入操作提供空间。

### 5. 领取迁移任务
每个参与扩容的线程会根据计算出的步长领取一定范围的索引位置进行数据迁移。这些索引范围确定了每个线程负责迁移的桶。

### 6. 数据迁移
线程将老数组中的每个桶内的所有节点迁移到新数组。由于`ConcurrentHashMap`使用链表或红黑树来处理冲突，所以需要重新计算每个节点的位置，并将其放置在新数组的正确位置上。

### 7. 完成迁移
每个桶迁移完成后，线程将在原位置留下一个特殊的迁移完成标记。这有助于其他线程知道哪些桶已经处理完毕。

### 8. 扫尾检查
一旦所有数据都迁移到了新数组，最后一个完成迁移的线程将执行最终检查，确认没有遗漏任何数据。

### 9. 切换到新数组
完成所有迁移工作后，`ConcurrentHashMap`的引用切换到新的数组，老数组将被垃圾收集器回收。

这种扩容策略通过允许多个线程并发扩容，显著减少了单个线程负载并优化了性能。此外，它还避免了长时间的锁定，使得`ConcurrentHashMap`在高并发环境中表现出色。

# 二十六、ConcurrentHashMap获取数据

# 二十七、CountDownLatch 和 CyclicBarrier

这两种同步辅助类在Java的`java.util.concurrent`包中，它们用于在并发编程中管理复杂的同步需求。虽然它们在一些方面相似，但用途和工作方式有所不同。

#### CountDownLatch
`CountDownLatch`是一个同步辅助类，用于允许一个或多个线程等待直到在其他线程中进行的一组操作完成。

- **工作原理**：在创建时其构造函数接受一个整数作为计数器，调用`countDown()`方法会将计数器减1，当计数器达到0时，所有等待的线程或单个线程将被释放，可以继续执行。
- **应用场景**：例如，在开始处理之前等待必要的资源全部初始化。

```java
CountDownLatch latch = new CountDownLatch(3);

for (int i = 0; i < 3; i++) {
    new Thread(() -> {
        System.out.println(Thread.currentThread().getName() + " is working.");
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
        latch.countDown();
    }).start();
}

latch.await();  // 等待所有线程完成任务
System.out.println("All prerequisites are done.");
```

#### CyclicBarrier
`CyclicBarrier`是一个同步辅助类，它允许一组线程相互等待，直到所有线程都达到了公共屏障点（Barrier Point）。

- **工作原理**：在创建时其构造函数接受一个整数，表示需要在屏障处同步的线程数量。可选地，可以提供一个在所有线程到达屏障时首先执行的barrier action（一种Runnable）。
- **应用场景**：用于多个并行任务，你想在继续处理前让所有任务都达到一个共同点，例如在多阶段运算中，必须等前一阶段的所有计算完成才能进行下一阶段。

```java
CyclicBarrier barrier = new CyclicBarrier(3, () -> {
    System.out.println("All parties are arrived at barrier, lets play");
});

for (int i = 0; i < 3; i++) {
    new Thread(() -> {
        System.out.println(Thread.currentThread().getName() + " is waiting at barrier");
        try {
            barrier.await();
        } catch (InterruptedException | BrokenBarrierException e) {
            e.printStackTrace();
        }
        System.out.println(Thread.currentThread().getName() + " has crossed the barrier");
    }).start();
}
```

# 二十八、Semaphore

`Semaphore`是一个计数信号量，从概念上将，它维持了一个许可集。信号量主要用于两个目的：一个是用于多个共享资源的互斥使用，另一个是用于并发线程数的控制。

- **工作原理**：在创建`Semaphore`时，你可以指定许可的初始数量。线程可以通过调用`acquire()`方法获取许可，如果没有许可可用，那么`acquire()`会阻塞直到有许可成为可用。线程可以通过调用`release()`来释放它持有的许可。
- **应用场景**：控制同时访问某个特定资源的操作数量，或者执行某个操作的线程数量。

```java
Semaphore semaphore = new Semaphore(2);

Runnable task = () -> {
    try {
        semaphore.acquire();
        System.out.println("Semaphore acquired by " + Thread.currentThread().getName());
        Thread.sleep(2000); // Simulating a task
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    } finally {
        semaphore.release();
        System.out.println("Semaphore released by " + Thread.currentThread().getName());
    }
};

new Thread(task).start();
new Thread(task).start();
new Thread(task).start();
```
