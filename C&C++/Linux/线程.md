# 学习目标

> 了解线程概念，理解线程与进程区别与联系。 
>
> 掌握基本的线程控制，理解互斥和同步
>
> 了解线程分离和线程安全概念
>
> 掌握生产消费模型
>
> 掌握使用互斥量，条件变量，posix信号量 
>
> 了解基于读写锁的读者写者问题

# 线程概念

> ==线程（thread）是系统任务调度的基本单位==，是进程内的一个独立执行流。线程在进程内部运行，本质是在进程地址空间内运行 。一个进程可以包含多个线程，每个线程都有自己的执行路径、栈空间和寄存器状态，但它们共享进程的虚拟地址空间和资源。

### 1、特点

#### 1）轻量级

> 相对于进程（PCB）来说，线程（LWB）是轻量级的执行单位，本质上也是task_struct结构，但在CPU眼里线程更加轻量化。因此线程的创建和切换开销比进程小，线程间的通信和同步也更加高效。

#### 2）共享资源

> 线程在同一个进程中共享相同的虚拟地址空间，因此它们可以直接访问进程的代码段、数据段，共享库以及共享的堆内存和文件描述符等内核资源。
>
> 也意味着多个线程可能同时访问某一资源，需要加以控制。

#### 3）相对独立性

> 在多线程环境中，每个线程都有自己的独立执行路径，它们可以并发执行，相互之间的操作不会直接干扰或影响彼此。
>
> ==独立的栈空间==：每个线程都有自己的栈空间，用于存储局部变量、函数调用的上下文和函数参数等信息，可以并发执行不同的函数或任务。
>
> 独立的寄存器状态：每个线程有自己的寄存器状态即上下文数据，包括通用寄存器、程序计数器和其他特殊寄存器。
>
> 其他独立的资源：线程id、errno、信号屏蔽字、调度优先级等内核资源
>
> 但注意线程的独立性是需要控制的，采取适当的同步机制（如互斥锁、信号量、条件变量）来保证多个线程之间对共享资源的访问是有序和互斥的，以避免竞态条件和数据二义性问题。

### 2、与进程关系

进程和线程都是操作系统中进行并发编程的基本单位，但它们在资源管理、执行、开销等方面存在一些关键区别：

#### （1）定义和概念

- **进程**：进程是操作系统进行资源分配和调度的一个独立单位，是一个程序关于某数据集合上的一次运行活动，是==系统进行资源分配和调度的基本单位==。每个进程都有自己的地址空间、内存、数据栈以及其他用于跟踪执行的辅助数据。
- **线程**：线程是进程的执行单元，==是进程中的实际运行单位==，负责程序的执行。一个进程可以包含多个线程，它们共享进程的地址空间和资源，但每个线程有自己的执行栈和程序计数器。

#### （2）资源分配和共享
- **进程**：==进程间资源是独立的==。每个进程拥有独立的代码和数据空间（即地址空间），进程间通信(IPC)需要特定的机制如管道、消息队列、共享内存等。
- **线程**：==同一进程的线程间共享进程的资源，如内存和文件描述符等==。线程间可以直接读写进程数据段（如全局变量）来进行通信，无需特殊的IPC机制。

#### （3）开销和性能
- **进程**：创建或销毁进程的开销比线程大，进程间的上下文切换成本也比线程间高。进程间切换需要更多时间和资源，因为涉及到更多的CPU时间和内存操作。
- **线程**：线程的创建、销毁和切换的开销相对较小，性能也更高。线程间切换不需要切换内存上下文，可以更快地进行。

#### （4）控制和调度
- **进程**：操作系统独立调度和控制每个进程，为每个进程提供独立的执行环境。进程拥有自己的程序计数器、系统栈以及状态信息。
- **线程**：在进程内，线程调度通常由进程自己进行管理，但最终的执行仍然由操作系统内核进行时间分配。线程共享相同的执行环境。

#### （5）并发性
- **进程**：多进程并发执行可以在多核处理器系统中实现更好的并行性，但进程间的资源隔离意味着高成本的通信和同步。
- **线程**：多线程并发执行同样可以利用多核处理器的优势，由于线程间共享大部分资源，它们之间的通信和同步成本较低，但这也可能导致竞争条件和同步问题。

### 3、优/缺点

#### 1）线程优点

> 轻量：创建、切换代价小，占用资源少
>
> 共享资源和通信：线程可以共享同一进程的资源，如内存空间、文件描述符等，简化了资源共享和通信的过程。线程之间可以通过共享内存进行快速的数据交换和通信。
>
> 并发：效率高、响应快
>
> 用途：
>
> 计算密集型应用，为了能在多处理器系统上运行，将计算分解到多个线程中实现
>
> I/O密集型应用，为了提高性能，将I/O操作重叠。线程可以同时等待不同的I/O操作。

#### 2）线程缺点

> 性能损失：线程之间的频繁切换可能引入一定的开销。当线程数量增多时，而处理器较少，开销可能会成为系统的瓶颈，可能会占用大量的系统资源。这里的性能损失指的是增加了额外的同步和调度开销，而可用的处理器资源不变。
>
> 线程安全性：在多线程环境下，共享资源的访问需要进行==同步和互斥操作==，以避免数据竞争和保证线程安全。
>
> 编程难度提高：编写与调试一个多线程程序比单线程程序困难得多

### 4、线程异常

> 单个线程如果出现除零，野指针问题导致线程崩溃，进程也会随着崩溃 
>
> 线程是进程的执行分支，线程出异常，就类似进程出异常，进而触发信号机制，终止进程，进程终止，该进程内的所有线程也就随即退出，健壮性或鲁棒性较低

# 线程控制

### 1、线程库的相关函数调用

#### 1）线程创建和销毁函数

> - `pthread_create()`：创建一个新的线程，并指定线程的执行函数和参数。
> - `pthread_exit()`：在线程执行函数中调用，用于终止当前线程的执行并返回退出状态。区分`exit()`进程退出
> - `pthread_detach()`：线程分离，不需要该线程的退出状态，如果主线程退出，其他线程也会退出
> - `pthread_join()`：等待指定的线程终止，并获取其退出状态。
> - `pthread_cancel()`：向指定线程发送取消请求，请求线程终止执行。
>

#### 2）互斥函数

> - `pthread_mutex_init()`：初始化互斥锁，用于保护共享资源，确保线程之间的互斥访问。
> - `pthread_mutex_lock()`：获取互斥锁，如果锁已经被其他线程占用，则当前线程会阻塞等待。
> - `pthread_mutex_unlock()`：释放互斥锁，允许其他线程获取该锁。
> - `pthread_mutex_destroy()`：关闭互斥锁，锁无法再使用。
>

#### 3）条件变量函数

> - `pthread_cond_init()`：初始化条件变量，用于线程之间的条件等待和通知。
> - `pthread_cond_wait()`：等待条件变量满足特定条件，进入等待状态，并释放相应的互斥锁。
> - `pthread_cond_signal()`：向等待在条件变量上的线程发送信号，唤醒其中一个线程继续执行。
> - `pthread_cond_broadcast()`：向等待在条件变量上的所有线程发送广播信号，唤醒所有等待线程。

#### 4）信号量函数

> - `sem_init()`：初始化一个信号量，设置初始值。
> - `sem_destroy()`：销毁一个信号量。
> - `sem_wait()`：执行 P 操作，将信号量的计数值减一。如果计数值变为负数，则阻塞当前线程
> - `sem_post()：`执行 V 操作，将信号量的计数值加一。如果有其他线程在等待该信号量，则唤醒其中一个线程。

### 2、线程互斥与同步

#### 1）互斥锁

> 在Linux操作系统中，互斥（Mutex）是一种保护机制，主要用于保护临界区，以==防止多个线程同时访问共享资源导致的数据不一致==。
>
> 一条交换语句，将锁数据交互到寄存器内部，本质是将数据共享变成自己的上下文数据即变成私有的资源预定机制
>

**互斥的主要作用如下：**

> 1. **==资源访问控制==**：当多个线程需要访问共享资源（例如，全局变量，文件，数据库连接等）时，互斥锁可以保证每次只有一个线程可以访问。这确保了数据的完整性和一致性。
>2. **==保证原子操作==**：互斥锁可以确保某一段代码（即临界区）的执行是原子的，即在一个线程执行该段代码的过程中不会被其他线程打断。这对于一些需要多个步骤同时成功或同时失败的操作非常重要。
> 4. **==线程间的同步==**：互斥锁也可以用于控制线程的执行顺序，确保一些需要在其他操作完成后才能进行的操作能按照预期顺序执行。
>
> 总的来说，互斥在并发编程中是一种重要的工具，它能够帮助开发者编写出正确，可预测且不含竞态条件的多线程应用程序。

#### 2）抢票

```c++
#include <pthread.h>
#include <iostream>
#include <unistd.h>
#include <string>
#include <cstdlib>
#include <cstring>
#include "lock.hpp"
using namespace std;
int ticket =10000;
typedef struct threadData   //存储线程数据，针对于锁是局部初始化，或者其他需要向线程传递信息
{
    char name[64];  //线程name
    pthread_mutex_t *pmutex;  //互斥锁指针
}threadData;
void *start_routine(void* arg)
{
    pthread_detach();
    threadData *data=static_cast<threadData*>(arg);
    while(true)
    {
        //Lock mylock(&mymutex)基于RAII思想的锁的封装
        pthread_mutex_lock(data->pmutex);//开锁
        if(ticket>0)
        {
            usleep(1000);
            cout<<data->name<<"线程抢到票了,当前线程为:"<<data->name<<" 票的编号为："<<ticket<<endl;
            ticket--;
            pthread_mutex_unlock(data->pmutex);//解锁
            usleep(123);
        }        
        else
        {
            cout<<"没有票了"<<endl;
            pthread_mutex_unlock(data->pmutex);  //解锁 
            break;
        }
    }
    cout<<"线程结束"<<endl;
    return nullptr;
}
int main()
{
    pthread_mutex_t mutex;
    pthread_mutex_init(&mutex,nullptr);//初始化锁
    pthread_t tid1,tid2,tid3,tid4;
    threadData *d1=new threadData();
    threadData *d2=new threadData();
    threadData *d3=new threadData();
    threadData *d4=new threadData();
    strcpy(d1->name,"thread 1");
    strcpy(d2->name,"thread 2");
    strcpy(d3->name,"thread 3");
    strcpy(d4->name,"thread 4");
    d1->pmutex=&mutex;
    d2->pmutex=&mutex;
    d3->pmutex=&mutex;
    d4->pmutex=&mutex;
    pthread_create(&tid1,nullptr,start_routine,d1);
    pthread_create(&tid2,nullptr,start_routine,d2);
    pthread_create(&tid3,nullptr,start_routine,d3);
    pthread_create(&tid4,nullptr,start_routine,d4);
    pthread_join(tid1,nullptr);
    pthread_join(tid2,nullptr);
    pthread_join(tid3,nullptr);
    pthread_join(tid4,nullptr);
    pthread_mutex_destroy(&mutex);
    return 0;
}
```

#### 3）基于RAII的封装

将互斥锁的实现(`Mutex`类)和锁的管理(`Lock`类)拆分成两个类是一种常见的设计模式，通常称为“范围锁”（Scope Lock）模式或“守卫对象”（Guard Object）模式。

在C++中，对象的生命周期管理遵循RAII（资源获取即初始化）原则，意味着资源的获取和释放是通过对象的构造函数和析构函数自动管理的。

`Lock`类的设计利用了RAII原则，确保在`Lock`对象的生命周期开始时自动获取锁（在构造函数中调用`_mutex->lock()`），并在生命周期结束时自动释放锁（在析构函数中调用`_mutex->unlock()`）。这样，即使在复杂的函数中发生异常，锁资源也能被正确释放，避免死锁。

`Mutex`类专注于互斥锁的创建、锁定、解锁和销毁等基本操作，而`Lock`类则负责管理锁的生命周期和作用范围，这样的分离使得每个类的职责更加清晰。这种设计允许在不修改`Mutex`类的情况下，引入不同类型的锁管理策略，例如，尝试锁定、定时锁定等。



```c++
#pragma once
#include <pthread.h>
#include <iostream>
class Mutex
{
public:
    Mutex()
    {
        pthread_mutex_init(&_lock,nullptr);
    }
    void lock()
    {
        pthread_mutex_lock(&_lock);
    }
    void unlock()
    {
        pthread_mutex_unlock(&_lock);
    }
    ~Mutex()
    {
        pthread_mutex_destroy(&_lock);
    }
private:
    pthread_mutex_t _lock;
};
class Lock
{
public:
    Lock(Mutex* mutex)
    :_mutex(mutex)
    {
        _mutex->lock();
    }
    ~Lock()
    {
        _mutex->unlock();
    }
private:
    Mutex* _mutex;
};
```





#### 4）可重入函数与线程安全

线程安全：==多个线程并发同一段代码时==，不会出现不同的结果。常见对全局变量或者静态变量进行操作， 并且没有锁保护的情况下，会出现该问题。 

可重入函数（Reentrant Function）是指在==多个线程同时调用时，能够保证函数执行的正确性和可预期性==，不会产生竞态条件或数据不一致的问题。可重入函数的设计要考虑线程安全性和数据共享的问题。

`volatile` 是一个关键字，用于在编程中声明一个变量是易变的（Volatile）。它告诉编译器不要对该变量进行优化，以确保每次访问变量时都从内存中读取最新的值，并在每次写入变量时将其立即写回内存。保持内存的可见性

**常见情况：**

**常见的线程不安全的情况：**

不保护共享变量的函数 

函数状态随着被调用，状态发生变化的函数 

返回指向静态变量指针的函数 

调用线程不安全函数的函数 

**常见的线程安全的情况：** 

每个线程对全局变量或者静态变量只有读取的权限，而没有写入的权限，一般来说这些线程是安全的 

类或者接口对于线程来说都是原子操作 

多个线程之间的切换不会导致该接口的执行结果存在二义性 

**常见不可重入的情况 ：**

调用了malloc/free函数，因为malloc函数是用全局链表来管理堆的 

调用了标准I/O库函数，标准I/O库的很多实现都以不可重入的方式使用全局数据结构 

可重入函数体内使用了静态的数据结构 

**常见可重入的情况：** 

不使用全局变量或静态变量 不使用malloc或者new开辟出的空间 

不调用不可重入函数不返回静态或全局数据，所有数据都有函数的调用者提供 使用本地数据，或者通过制作全局数据的本地拷贝来保护全局数据

**联系：**

> 函数是可重入的，那就是线程安全的。函数是不可重入的，那就不能由多个线程使用，有可能引发线程安全问题，如果一个函数中有全局变量，那么这个函数既不是线程安全也不是可重入的。 可重入与线程安全区别 可重入函数是线程安全函数的一种 线程安全不一定是可重入的，而可重入函数则一定是线程安全的。 如果将对临界资源的访问加上锁，则这个函数是线程安全的，但如果这个重入函数若锁还未释放则会产生 死锁，因此是不可重入的。

#### 5）死锁问题

> ==死锁是指在一组进程中的各个进程均占有不会释放的资源，但因互相申请被其他进程所站用不会释放的资源而处于的一种永久等待状态。==

**死锁四个必要条件：**

> 互斥条件：一个资源每次只能被一个执行流使用 
>
> 请求与保持条件：一个执行流因请求资源而阻塞时，对已获得的资源保持不放 
>
> 不剥夺条件:一个执行流已获得的资源，在末使用完之前，不能强行剥夺 
>
> 循环等待条件:若干执行流之间形成一种头尾相接的循环等待资源的关系 

### 3、互斥锁公平问题

#### 1）多线程的问题

> 互斥可能导致饥饿问题：某个线程由于无法获取所需的资源或执行时间片，而无法正常执行的情况。其他线程可能长时间占用资源或高优先级线程持续抢占 CPU 时间，导致某个线程无法得到应有的资源或执行机会，从而无法继续执行。

#### 2）条件变量

> 条件变量（Condition Variable）是一种线程同步机制，用于线程之间的等待和通知。条件变量允许线程在满足特定条件之前等待，并在条件满足时被其他线程通知唤醒。
>
> 若想改变状态必然涉及其他线程对共享资源的访问，条件变量通常与互斥锁（Mutex）结合使用，以实现更复杂的线程同步和协作。
>
> 条件（对应共享资源的状态，由程序员控制）、条件变量（条件满足或不满足，选择进行wait和signal）
>
> 条件变量的使用可以实现更灵活的线程同步和协作，允许线程在满足特定条件之前等待，避免了轮询的开销和饥饿锁的产生。它常用于生产者-消费者模式、线程间消息传递和资源共享等场景，能够提供高效的线程间通信和同步。然而，使用条件变量时需要注意正确的互斥锁使用和条件的精确判断，以避免竞态条件和死锁等问题。
>
> 竞态条件：时序问题导致程序异常

#### 3）信号量

> 信号量（Semaphore）是一种用于线程同步和互斥的计数器。它提供了一种简单而有效的机制，用于控制对共享资源的访问，避免竞态条件和实现线程之间的互斥和协作。

**信号量维护一个整型计数器和一个等待队列，可以执行以下两种操作：**

> 1. P 操作（等待操作）：当一个线程希望访问共享资源时，它会执行 P 操作，即减少信号量的计数器。如果计数器的值变为负数，表示资源不可用，该线程将被阻塞并加入等待队列。
> 2. V 操作（释放操作）：当一个线程使用完共享资源后，它会执行 V 操作，即增加信号量的计数器。如果有线程在等待队列中等待资源，V 操作将唤醒一个或多个等待线程，使其继续执行。

**信号量常用于以下几个场景：**

> 1. 互斥锁（Mutex）：可以使用二值信号量（计数器为1）来实现互斥锁的功能。当计数器为0时，表示锁被占用，其他线程需要等待释放锁的信号。
> 2. 限制并发访问：可以使用计数型信号量（计数器大于1）来控制对共享资源的并发访问数量。计数器的初始值决定了允许同时访问资源的线程数。
> 3. 解决生产者-消费者问题：通过使用信号量来进行生产者和消费者之间的同步和协作，确保生产者和消费者之间的正确交互和资源管理。与阻塞队列相比，利用信号量的环形队列有在共享资源区并发的特点

# 生产消费模型

在生产者-消费者模型中，生产者和消费者通过共享缓冲区进行交互，其中涉及到两个主要的同步问题：一是确保共享缓冲区的线程安全访问，二是协调生产者和消费者之间的工作节奏以防止缓冲区的过度填充或耗尽。为了解决这些问题，通常会使用锁（互斥量）和条件变量。下面详细解释整个过程：

使用锁确保互斥访问

- 当生产者准备向共享缓冲区添加一个产品时，它首先需要获取一个锁，以防止其他线程（其他生产者或消费者）同时修改缓冲区。这保证了在任何时刻只有一个线程能操作共享缓冲区，从而确保了线程安全。

使用条件变量同步生产和消费

- 如果共享缓冲区已满，生产者无法立即添加新产品。此时，生产者会等待一个“缓冲区不满”的条件。在等待这个条件时，生产者会释放之前获取的锁，这允许消费者进入临界区消费产品。
- 消费者从共享缓冲区取出产品后，会检查缓冲区是否有空位。如果有，消费者会通知正在等待“缓冲区不满”条件的生产者。
- 同样，如果共享缓冲区为空，消费者需要等待“缓冲区非空”的条件，等待过程中会释放锁以允许生产者生产产品。

唤醒等待的线程

- 当消费者消费了产品后，会通知等待“缓冲区非空”条件的线程（可能有多个生产者和消费者在等待）。同样，当生产者生产了产品并且缓冲区还未满时，它会通知等待“缓冲区不满”条件的线程。

锁（互斥量）用于确保对共享缓冲区的互斥访问，而条件变量用于同步生产者和消费者之间的操作。在等待条件变量时释放锁是必要的，以允许其他线程进入临界区。通过`while`循环重新检查条件，确保线程在条件真正满足时才执行相关操作，这是实现高效且安全的生产者-消费者模型的关键。

## **1.基于阻塞队列的产品模型**

**以下是生产者-消费者模型的基本原则和关键组件：**

> 1. 共享缓冲区（Shared Buffer）：生产者和消费者之间共享的数据存储区域。它可以是一个队列、缓冲池或其他数据结构，用于存储生产者生产的数据，供消费者消费。
> 2. 互斥锁（Mutex）：用于保护对共享缓冲区的访问，确保在同一时间只有一个线程可以对缓冲区进行读取或写入操作，避免竞态条件。
> 3. 满/空信号量（Full/Empty Semaphore）：用于表示缓冲区的状态。满信号量记录缓冲区中可消费的数据数量，空信号量记录缓冲区中可生产的空闲位置数量。
> 4. 生产者线程（Producer Thread）：负责生成数据并将其放入共享缓冲区。当缓冲区已满时，生产者线程会等待直到有可用的空闲位置。
> 5. 消费者线程（Consumer Thread）：负责从共享缓冲区中获取数据并进行处理。当缓冲区为空时，消费者线程会等待直到有可消费的数据。

**基本的生产者-消费者模型的流程如下：**

> 1. 初始化互斥锁和信号量，并设置缓冲区的初始状态。
> 2. 启动生产者线程和消费者线程。
> 3. 生产者线程生成数据并尝试将其放入缓冲区。如果缓冲区已满，则生产者线程等待空信号量。
> 4. 消费者线程从缓冲区中获取数据并进行处理。如果缓冲区为空，则消费者线程等待满信号量。
> 5. 在生产者线程放入数据后，更新满信号量和空信号量的值，以反映缓冲区的状态变化。
> 6. 在消费者线程处理完数据后，同样更新满信号量和空信号量的值。
> 7. 重复步骤3到步骤6，直到生产者完成所有数据的生产并退出，或消费者完成所有数据的消费并退出。



**BlockQueue.hpp**

```c++
#pragma once
#include <queue>
#include <pthread.h>
#include<unistd.h>
#include<iostream>
using namespace std;
const uint32_t defaultCap=5;
template <class T>
class BlockQueue
{
public:
    BlockQueue(uint32_t capacity=defaultCap)
        :_capacity(cap)
    {
        pthread_mutex_init(&_mutex,nullptr);
        pthread_cond_init(&_proCond,nullptr);
        pthread_cond_init(&_consumerCond,nullptr);
    }
    ~BlockQueue()
    {
        pthread_mutex_destroy(&_mutex);
        pthread_cond_destroy(&_proCond);
        pthread_cond_destroy(&_consumerCond);
    }
    //生产
    void push(T in)
    {
        //加锁
        lock();
        //判断:满不生产，不满生产
        while(isFull())//被调用之后，需要检查条件是否已经满足。
        {
            //满---等待
            proBlockWait();
        }
        //生产
        produce(in);
        //解锁
        unlock();
        //唤醒消费者
        weakUpCon();
    }
    //消费
    T pop()
    {
        lock();
        while(isEmpty())
        {
            consumerBlockWait();
        }
        //消费
        T out=consume();
        unlock();
        weakUpPro();
        return out;
    }
private:
    void lock()
    {
        pthread_mutex_lock(&_mutex);
    }
    void unlock()
    {
        pthread_mutex_unlock(&_mutex);
    }
    bool isFull()
    {
        return _cap==_bq.size();
    }
    bool isEmpty()
    {
        return _bq.size()==0;
    }
    void proBlockWait()
    {
        pthread_cond_wait(&_proCond,&_mutex);
    }
    void consumerBlockWait()
    {
        pthread_cond_wait(&_consumerCond,&_mutex);
    }
    void produce(T in)
    {
        _bq.push(in);
    }
    T consume()
    {
        T tmp=_bq.front();
        _bq.pop();
        return tmp;
    }
    void weakUpCon()
    {
        pthread_cond_signal(&_consumerCond);
    }
    void weakUpPro()
    {
        pthread_cond_signal(&_proCond);
    }
private:
    queue<T>_bq;
    uint32_t _capacity;
    pthread_mutex_t _mutex;
    pthread_cond_t _proCond;
    pthread_cond_t _consumerCond;
};
```

注意：使用while进行检查是为了防止以下情况

假唤醒是指线程在没有接收到明确的唤醒信号时自动醒来。这是线程等待/唤醒机制的一种已知问题，在某些操作系统和多线程环境下可能发生。如果你使用`if`语句来检查条件，那么在假唤醒后，线程会继续执行后面的代码，即使条件实际上并未满足。这可能导致数据不一致或其他线程安全问题。即使没有发生假唤醒，等待的线程被唤醒时，它所等待的条件可能已经不再满足。这可能是因为多个线程等待同一个条件，而在当前线程被唤醒之前，另一个线程已经改变了这个条件。使用`while`循环可以在每次唤醒时重新检查条件，确保条件真正满足时才继续执行。

当一个线程被条件变量的通知唤醒时，它需要重新获取之前释放的锁才能继续执行。由于多个线程可能同时被唤醒，或者在等待期间缓冲区的状态可能已经改变（例如，其他线程插队访问了缓冲区），所以唤醒后需要重新检查条件是否仍然满足。

**BlockQueue**

```c++
#include "BlockQueue.hpp"
#include "Task.hpp"
#include<time.h>
#include<cstdlib>
const string ops="+-*/%";
void* produce(void* arg)
{
    //BlockQueue<int>*pbq=static_cast<BlockQueue<int>*>(arg);
    BlockQueue<Task>*pbq=static_cast<BlockQueue<Task>*>(arg);
    while(true)
    {
        sleep(1);
        //制造数据
        //int data=rand()%10;
        int d1=rand()%10;
        int d2=rand()%10;
        char op=ops[rand()%5];
        Task t(d1,d2,op);
        //生产
        //pbq->push(data);
        pbq->push(t);
        //cout<<"生产成功，生产了："<<data<<endl;
        cout<<"添加任务成功"<<d1<<op<<d2<<"=?"<<endl;
    }
    return nullptr;
}
void *consume(void* arg)
{
    //BlockQueue<int>*pbq=static_cast<BlockQueue<int>*>(arg);
    BlockQueue<Task>*pbq=static_cast<BlockQueue<Task>*>(arg);
    //消费
    while(true)
    {
        //sleep(1);
        //int tmp=pbq->pop();
        Task tmp=pbq->pop(); 
        int result=tmp();
        int d1,d2;
        char op;
        tmp.get(&d1,&d2,&op);
        cout<<"调用任务成功"<<d1<<op<<d2<<"="<<result<<endl;
    }
    return nullptr;
}
int main()
{
    // BlockQueue<int> bq;
    BlockQueue<Task> bq;
    srand(time(nullptr));
    pthread_t t1,t2;
    pthread_create(&t1,nullptr,produce,(void*)&bq);
    pthread_create(&t2,nullptr,consume,(void*)&bq);
    pthread_join(t1,nullptr);
    pthread_join(t2,nullptr);
    return 0;
}
```

## 2.**基于环形队列的生产消费模型**

基于环形队列的生产者-消费者模型是一种常见的并发模式，用于处理生产者和消费者之间的数据交换。环形队列（也称为循环缓冲区）作为共享资源，其主要特点是队列的首尾相连，形成一个闭环。这种数据结构在多线程环境下特别有用，因为它可以有效地管理数据的存储和传输，同时最小化锁的使用以提高效率。下面是该模型的具体实现过程：

环形队列是一种固定大小的队列，其操作在达到队列末尾时会自动回绕到开始位置。这使得环形队列能够在不需要移动元素的情况下复用空间，非常适合作为缓冲区使用。

1. **共享缓冲区**：环形队列本身，生产者向其中添加元素，消费者从中移除元素。
2. **互斥锁**（Mutex）：保证在任何时刻只有一个线程可以访问共享缓冲区。
3. **条件变量**：用于协调生产者和消费者之间的工作节奏。通常需要两个条件变量，一个表示“缓冲区非满”（用于生产者），另一个表示“缓冲区非空”（用于消费者）。

操作过程

1. **生产者操作**：
    - 生产者在向环形队列添加元素之前，首先需要获取互斥锁。
    - 检查队列是否已满。如果队列满了，生产者就在“缓冲区非满”条件变量上等待，同时释放互斥锁以允许其他线程（如消费者）运行。
    - 当队列非满时，生产者向队列中添加元素，更新队列的状态（如头尾指针），然后通知可能正在等待的消费者（通过“缓冲区非空”条件变量）。
    - 生产者操作完成后释放互斥锁。

2. **消费者操作**：
    - 消费者在从环形队列移除元素之前，同样需要获取互斥锁。
    - 检查队列是否为空。如果队列为空，消费者就在“缓冲区非空”条件变量上等待，同时释放互斥锁以允许其他线程（如生产者）运行。
    - 当队列非空时，消费者从队列中取出元素，更新队列的状态，然后通知可能正在等待的生产者（通过“缓冲区非满”条件变量）。
    - 消费者操作完成后释放互斥锁。

**RingQueue.hpp**

```c++
#pragma once
#include <iostream>
#include <pthread.h>
#include <semaphore.h>
#include<unistd.h>
#include <vector>
using namespace std;
uint32_t defaultCap=5;
template<class T>
class RingQueue
{
public:
    RingQueue(uint32_t cap=defaultCap)
        :_rq(cap)
        ,_indexData(0)
        ,_indexRoom(0)
    {
        pthread_mutex_init(&_mutexData,nullptr);
        pthread_mutex_init(&_mutexRoom,nullptr);
        sem_init(&_semData,0,0);
        sem_init(&_semRoom,0,_rq.size());
    }
    ~RingQueue()
    {
        pthread_mutex_destroy(&_mutexData);
        pthread_mutex_destroy(&_mutexRoom);
        sem_destroy(&_semData);
        sem_destroy(&_semRoom);
    }
public:
    void push(T in)
    {
        //P-room 
        sem_wait(&_semRoom);
        //加锁
        pthread_mutex_lock(&_mutexRoom);
        //放入
        _rq[_indexRoom++]=in;
        _indexRoom%=_rq.size();
        //解锁
        pthread_mutex_unlock(&_mutexRoom);
        //V-data
        sem_post(&_semData);
    }
    T pop()
    {
        sem_wait(&_semData);
        pthread_mutex_lock(&_mutexData);
        T out=_rq[_indexData++];
        _indexData%=_rq.size();
        pthread_mutex_unlock(&_mutexData);
        sem_post(&_semRoom);
        return out;
    }
private:
    vector<T> _rq;
    pthread_mutex_t _mutexData;
    pthread_mutex_t _mutexRoom;
    sem_t _semData;
    sem_t _semRoom;
    uint32_t _indexData;
    uint32_t _indexRoom;
};
```

**RingQueue**

```c++
#include "RingQueue.hpp"
#include<time.h>
#include<cstdlib>
void* produce(void* arg)
{
    RingQueue<int>*prq=static_cast<RingQueue<int>*>(arg);
    while(true)
    {
        int data=rand()%10;
        prq->push(data);
        cout<<"放入了一个数据："<<data<<endl;
    }
    return nullptr;
}
void *consume(void* arg)
{
    RingQueue<int>*prq=static_cast<RingQueue<int>*>(arg);
    while(true)
    {
        sleep(1);
        int tmp=prq->pop();
        cout<<"拿出了一个数据:"<<tmp<<endl;
    }
    return nullptr;
}
int main()
{
    RingQueue<int> rq;
    srand(time(nullptr));
    pthread_t t1,t2;
    pthread_create(&t1,nullptr,produce,(void*)&rq);
    pthread_create(&t2,nullptr,consume,(void*)&rq);
    pthread_join(t1,nullptr);
    pthread_join(t2,nullptr);
    return 0;
}
```

基于环形队列的生产者-消费者模型与普通队列模型的主要区别在于数据结构、内存利用效率、和处理环形逻辑的能力。

数据结构的差异

- **环形队列**：是一种固定大小的队列，它的首尾是相连的。当指针移动到队列的末端时，会自动回绕到队列的开始位置，形成一个环形结构。
- **普通队列**：通常是动态增长的，队列的末端不与开始相连。当队列满时，需要进行扩容或者拒绝新的元素插入。

内存利用效率

- **环形队列**：由于其固定的大小和环形结构，它能够高效地复用内存空间。一旦数据被消费，相应的空间即可重新用于存储新生产的数据，这使得环形队列特别适合作为缓冲区使用。
- **普通队列**：如果使用动态数组实现，可能需要不断地进行扩容操作，这涉及到内存的重新分配和数据的复制，效率较低。如果使用链表实现，则每个元素需要额外的空间存储指向下一个元素的指针，也增加了内存使用。

处理逻辑的差异

- **环形队列**：需要特别处理队列的回绕逻辑，即当生产者或消费者到达队列末尾时，需要自动回绕到队列的开头。这要求管理两个指针（或索引）：一个指向队列头部（消费者操作），另一个指向队列尾部（生产者操作）。
- **普通队列**：生产者总是在队列尾部插入新元素，消费者从队列头部移除元素。在动态数组实现中，可能需要处理元素的移动来避免空间的浪费。

适用场景的差异

- **环形队列**：由于其固定大小和高效的内存利用，环形队列特别适用于需要预先分配固定缓冲区的场景，如操作系统内核中的事件队列、网络数据包的缓冲处理等。
- **普通队列**：适用于元素数量动态变化、对内存使用没有严格限制的场景。动态队列可以根据需要增长，适合于不确定队列最大容量的应用。

## 3.线程池

线程池是一种==基于池化技术的软件设计模式==，旨在==减少在多线程程序中频繁创建和销毁线程的开销==。通过重用一组预先创建的线程来执行任务，线程池可以提高程序性能，增加程序的响应速度，并提供更好的系统资源管理。以下是线程池的基本概念和工作原理：

### （1）基本概念

- **线程池（Thread Pool）**：预先创建的线程集合，这些线程可以执行任何通过某种方式提交给它们的任务。
- **工作线程（Worker Threads）**：线程池中的线程，负责执行提交给线程池的任务。
- **任务队列（Task Queue）**：一个队列，用于存储待处理的任务。工作线程从队列中取出任务并执行。

### （2）工作原理

1. **初始化**：线程池在程序启动时或者首次使用时被创建，预先生成一定数量的工作线程。
2. **提交任务**：程序运行过程中，当需要执行一个任务时，该任务被封装成一个任务对象，然后被提交到线程池的任务队列中等待执行。
3. **任务分配**：工作线程周期性地检查任务队列，当队列中存在任务时，线程会取出并执行这些任务。
4. **执行任务**：被分配到任务的线程将执行任务直到完成，然后返回线程池等待下一个任务。
5. **调整线程数量**（可选）：一些线程池实现支持动态调整池中线程的数量，以适应不同的工作负载。

### （3）线程池的优点

- **降低资源消耗**：通过重用已经创建的线程，减少了创建和销毁线程的次数，降低了系统的资源消耗。
- **提高响应速度**：任务到达时，无需等待线程创建即可立即执行，从而提高了响应速度。
- **提高线程的可管理性**：线程是稀缺资源，通过集中管理可以避免因为线程过多导致的资源消耗过大和系统崩溃。

Task.hpp

```java
#pragma once

#include <iostream>
#include <string>

class Task
{
public:
    Task() : elemOne_(0), elemTwo_(0), operator_('0')
    {}
    Task(int one, int two, char op) : elemOne_(one), elemTwo_(two), operator_(op)
    {}
    int operator()()
    {
        int result = 0;
        switch (operator_)
        {
        case '+':
            result = elemOne_ + elemTwo_;
            break;
        case '-':
            result = elemOne_ - elemTwo_;
            break;
        case '*':
            result = elemOne_ * elemTwo_;
            break;
        case '/':
        {
            if (elemTwo_ == 0)
            {
                std::cout << "div zero, abort" << std::endl;
                result = -1;
            }
            else
            {
                result = elemOne_ / elemTwo_;
            }
        }
        break;
        case '%':
        {
            if (elemTwo_ == 0)
            {
                std::cout << "mod zero, abort" << std::endl;
                result = -1;
            }
            else
            {
                result = elemOne_ % elemTwo_;
            }
        }
        break;
        default:
            std::cout << "非法操作: " << operator_ << std::endl;
            break;
        }
        return result;
    }
    int get(int *e1, int *e2, char *op)
    {
        *e1 = elemOne_;
        *e2 = elemTwo_;
        *op = operator_;
    }
private:
    int elemOne_;
    int elemTwo_;
    char operator_;
};
```

**ThreadPool.hpp**

```c++
#include <pthread.h>
#include <queue>
#include <iostream>
#include "Task.hpp"
using namespace std;
uint32_t defaultNum=5;
template <class T>
class ThreadPool
{
private:
    //构造函数私有
    ThreadPool(uint32_t num=defaultNum)
        :_threadNum(num)
    {
        pthread_mutex_init(&_mutex,nullptr);
        pthread_cond_init(&_cond,nullptr);
    }
    //单例模式:懒汉,调用时实例化
    //防止拷贝
    ThreadPool(const ThreadPool<T> &)=delete;
    //防止赋值
    void operator=((const ThreadPool<T> &)=delete;
public:
    static ThreadPool<T> *getInstance()
    {
        static Mutex mutex;
        if(nullptr==_instance)
        {
            //基于RAII思想封装的锁
            Lock lock(&mutex);
        	if(nullptr==_instance)
        	{
            	_instance=new ThreadPool<T>();
        	}
        }
    }
    static void *threadRoutine(void *arg)
    {
        //线程分离，不需要join
        pthread_detach(pthread_self());
        //类型转化static_cast<>()
        ThreadPool<T>* ptp=static_cast<ThreadPool<T>*>(arg);
        while(true)
        {
            //任务队列加锁
            ptp->lockQueue(); 
            //任务队列是否为空
            while(ptp->isEmpty())
            {
                //为空则条件等待，并释放锁
                ptp->waitTask();
                //唤醒后则又加锁
            }
            //“消费”任务
            T tmp=ptp->pop();
            //任务队列解锁
            ptp->unlockQueue();
            int result =tmp();
            int d1,d2;
            char op;
            tmp.get(&d1,&d2,&op);
            cout<<pthread_self()<<":执行任务:"<<d1<<op<<d2<<"="<<result<<endl;
        }
    }
    void start()
    {
        //生产多线程
        for(uint32_t i=0;i<_threadNum;i++)
        {
            pthread_t t;
            pthread_create(&t,nullptr,threadRoutine,this);
        }
    }
    void push(const T& in)
    {
        //push公开，在类内实现加锁，方便使用
        lockQueue(); 
        _tq.push(in);
        choiceThread();
        unlockQueue();
    }
    ~ThreadPool()
    {
        pthread_mutex_destroy(&_mutex);
        pthread_cond_destroy(&_cond);
    }
private:
    T pop()
    {
        T out=_tq.front();
        _tq.pop();
        return out;
    }
    bool isEmpty()
    {
        return _tq.empty();
    }
    void lockQueue()
    {
        pthread_mutex_lock(&_mutex);
    }
    void unlockQueue()
    {
        pthread_mutex_unlock(&_mutex);
    }
    void waitTask()
    {
        pthread_cond_wait(&_cond,&_mutex);
    }
    void choiceThreadForHandler()
    {
        pthread_cond_signal(&_cond);
    }

private:
    uint32_t _threadNum;
    queue<T> _tq;
    pthread_mutex_t _mutex;
    pthread_cond_t _cond;
    static ThreadPool<T> *_instance;
};
template<class T>
ThreadPool<T> * ThreadPool<T> ::_instance=nullptr;
```



**ThreadPool.cpp**

```c++
#include "ThreadPool.hpp"
#include <cstdlib>
#include <time.h>
#include <memory>
#include <unistd.h>
const string ops="+-*/%";
int main()
{
    srand(time(nullptr));
    //unique_ptr<ThreadPool<Task>> tp(new ThreadPool<Task>());
    unique_ptr<ThreadPool<Task>> tp(getInstance());
    tp->start();
    while(true)
    {
        usleep(1000);
        int d1=rand()%20;
        int d2=rand()%10;
        char op=ops[rand()%5];
        cout<< "主线程派发计算任务: " << d1<< op << d2 << "=?" << endl;
        Task t(d1,d2,op);
        tp->push(t);
    }
}
```



# 其他线程安全

## 1.STL容器的线程安全

STL容器本身不提供内置的线程安全保证。这意味着在多线程环境中，对同一个容器对象的并发访问（特别是当至少一个线程正在修改容器时）需要外部同步机制来保证线程安全。简而言之：

- 同时从多个线程读取STL容器中的数据是安全的。
- 如果至少有一个线程正在修改容器，那么任何其他线程的访问（读取或修改）都需要通过互斥锁或其他同步机制进行保护。

## 2.智能指针的线程安全

对于智能指针，线程安全性的讨论主要集中在`std::shared_ptr`上，因为它涉及到引用计数的操作，而`std::unique_ptr`通常不用于多线程共享资源的场景。

- **`std::unique_ptr`**：是独占所有权的智能指针，不支持共享同一资源的多个指针实例，因此不涉及多线程间的共享和同步问题。使用`std::unique_ptr`的代码需要确保它不会在多个线程间共享。
  
- **`std::shared_ptr`**：支持多个指针实例共享同一资源，通过引用计数来管理资源的生命周期。`std::shared_ptr`的引用计数机制是线程安全的，意味着在多个线程中创建和销毁`std::shared_ptr`对象是安全的。然而，需要注意的是，虽然引用计数本身是线程安全的，但通过`std::shared_ptr`访问共享资源本身并不是线程安全的。如果多个线程需要通过`std::shared_ptr`修改共享资源，那么对资源的访问需要外部同步。

# 读写问题

读写问题（Readers-Writers Problem）是一个经典的同步问题，涉及到对共享数据的并发访问控制。这个问题的核心在于如何允许多个读操作并行执行以提高效率，同时确保写操作的互斥性，避免数据不一致。

问题分为两种情况：读者优先（Readers-Preference）、写者优先（Writers-Preference），还有一种更平衡的解决方案称为“公平”或“无偏好”访问。

### 1.问题描述

共享数据可以被多个读者（Reader）同时访问而不会引起数据不一致问题，但是写者（Writer）访问时则需要独占访问权，因为写操作可能改变数据状态，这要求：

1. **任何时候都可以有多个读者同时读取数据。**
2. **任何时候只允许一个写者操作数据。**
3. **如果有写者在等待，则应阻止新的读者开始读取数据（写者优先）。**

### 2.解决方案

#### 读者优先

这种策略允许最大限度的读并发，但可能导致写者饥饿，因为只要有新的读者到来，写者就可能被无限期延迟。

#### 写者优先

这种策略确保写请求尽快得到满足，减少了写者的等待时间，但可能导致读者饥饿，特别是在写者请求频繁时。

#### 无偏好（公平）

尝试平衡读者和写者的等待时间，确保无论是读者还是写者都不会遭受长时间的饥饿。通常通过队列或者条件变量实现，确保按请求到达的顺序获得访问权。

### 3.实现方法

读写问题的解决通常涉及互斥锁（Mutex）和条件变量（Condition Variables）。

- 使用一个互斥锁保护共享数据和内部状态（如读计数）。
- 使用条件变量控制读者和写者的访问。例如，一个条件变量用于等待读者完成，另一个用于等待写者完成。

### 示例代码（伪代码）

```cpp
mutex mtx; // 用于共享数据的互斥
condition_variable readCond, writeCond; // 读写条件变量
int activeReaders = 0, activeWriters = 0;
int waitingWriters = 0;

void startRead() {
    unique_lock<mutex> lk(mtx);
    while (activeWriters > 0 || waitingWriters > 0) {
        readCond.wait(lk);
    }
    activeReaders++;
}

void endRead() {
    unique_lock<mutex> lk(mtx);
    activeReaders--;
    if (activeReaders == 0 && waitingWriters > 0) {
        writeCond.notify_one();
    }
}

void startWrite() {
    unique_lock<mutex> lk(mtx);
    waitingWriters++;
    while (activeReaders > 0 || activeWriters > 0) {
        writeCond.wait(lk);
    }
    waitingWriters--;
    activeWriters++;
}

void endWrite() {
    unique_lock<mutex> lk(mtx);
    activeWriters--;
    if (waitingWriters > 0) {
        writeCond.notify_one();
    } else {
        readCond.notify_all();
    }
}
```

读写问题的解决方案需要细致考虑读写操作的公平性和效率，以防止饥饿和提高系统的吞吐量。
